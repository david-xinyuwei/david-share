##  





```
特性                          | NVFP4（NVIDIA Blackwell）                                          | MXFP4（OCP Microscaling）
-----------------------------|-------------------------------------------------------------------|-------------------------------------------------
元素数据类型                  | FP4 E2M1（1 位符号 + 2 位指数 + 1 位尾数）                          | FP4 E2M1（1 位符号 + 2 位指数 + 1 位尾数）
微块大小（Block size）        | 16                                                                | 32
微块缩放因子格式              | FP8 E4M3（支持非 2 的幂，小数缩放）                                 | E8M0（仅指数，2 的幂缩放，移位友好）
是否有全局缩放因子            | 有，全局 FP32 缩放（Per-tensor scale）                             | 无（仅微块缩放）
重构公式（dequantize）        | x ≈ xq × s_block(FP8) × s_tensor(FP32)                            | x ≈ xq × 2^k（k 来自 E8M0）
动态范围与鲁棒性              | 双缩放 + 小微块，更适应异质分布和异常值                            | 幂次缩放，小值保持较好，对异常值有抵抗力
计算代价（缩放应用）           | 需乘法运算（但 Blackwell 上 NVFP4 原生硬件加速）                     | 移位运算即可（极简高效），硬件需支持
硬件执行路径                  | Blackwell Tensor Cores 原生支持，全程 NVFP4 可免反量化               | 硬件支持依厂商不同，未必有原生直通
是否需反量化                  | 权重+激活均 NVFP4 时无需反量化；NVFP4A16 需反量化                    | 若硬件不支持直接执行，需先转换到高精度
吞吐表现（相对 INT4）         | ~2.3×（Blackwell + 全 NVFP4 激活/权重）                             | 依实现而定，资料未提供
精度表现                      | 与 FP8 精度几乎持平（多数基准误差 ≤1%）                              | 高于传统 INT4，具体对比 NVFP4 未有统一结论
平均存储开销                  | 约 4.5 bits/值（FP8 微块缩放 + FP32 全局缩放摊销后）                  | 通常低于 NVFP4（微块 32 + 幂次缩放元数据更省）
模型体积                      | 比常见 INT4（AWQ/AutoRound）大（如 Llama3.3 +7GB）                   | 比 NVFP4 小（依实现）
是否需校准数据                | 全量化需少量校准数据（128~512 样本），NVFP4A16 一般不需要              | 依实现；权重量化常可少/无校准，含激活量化一般需要
生态与工具支持                | llm-compressor 可量化，vLLM 支持推理，需 Blackwell 最优             | OCP 标准，llm-compressor 暂不支持，依厂商实现
适用场景                      | Blackwell 环境下追求极致吞吐+高精度保持                             | 跨平台、硬件多样化部署、算子实现需简单（移位）
```



